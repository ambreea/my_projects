<!DOCTYPE html>
<html>

<head>
	<title>Oamenii de știință avertizează! Ar putea fi imposibil să controlăm Inteligența Artifcială</title>
	<meta charset="utf-8">
	<link rel="stylesheet" type="text/css" href="stilizare.css">
	<link rel="stylesheet" type="text/css" href="stilizare2.css">
</head>

<body class="container-principal">

	<header class="container1">

		<div class="logo">
			<a href="proiect.html"><img src="logo.png" alt="logo" width="220" height="70"></a>
		</div>

		<div class="meniu">
			<nav >
				<a href="proiect.html">Home </a>
				<a href="animale.html">Animale </a>
				<a href="stiinta.html">Stiinta </a>
				<a href="https://www.accuweather.com/" target="_blank">Vremea </a>
				<a href="curs schimb.html" target="_blank">Curs  de schimb </a>		
				<a href="video.html">Video </a>	
			</nav>
		</div>

		<div class="cauta" id="cauta">
			<form action="script.aspx" method="post" enctype="multipart/form-data" name="cauta" target="_blank">
				<label for="cauta">Cauta: </label>
				<input type="search" name="cauta" id="search" placeholder="cauta...">
				<input type="submit" name="Trimite">
			</form>
		</div>

	</header>
	
	<section class="container2">			
	
		<article class="art">
			<h1>Oamenii de știință avertizează! Ar putea fi imposibil să controlăm Inteligența Artifcială</h1>
			
			<figure>
			<a href="Oamenii de știință avertizează! Ar putea fi imposibil să controlăm Inteligența Artifcială.html"><img src="inteligenta-artificiala.jpg"></a>
			<figcaption>Credit foto: Pixabay</figcaption>
			</figure>

			<p><b>Oamenii de știință de la Max Planck Society, o instituție europeană de cercetare de renume, spun că omenirea nu va putea niciodată să controleze o inteligență artificială superinteligentă care ar putea salva sau distruge omenirea.</b></p>

			<p>Cel puțin asta reiese conform cercetărilor publicate în Journal of Artificial Intelligence Research. Problema, spun cercetătorii, este că nu există nicio modalitate de a conține un astfel de algoritm fără o tehnologie mult mai avansată decât ceea ce putem construi astăzi.</p>

			<p>Echipa s-a concentrat în primul rând pe problema restricției. Dacă un algoritm atotputernic ar determina cumva că ar trebui să rănească oamenii sau, într-un mod mai apropiat de „Terminator”, să pună capăt omenirii cu totul, cum l-am împiedica să acționeze?</p>

			<h2>Ce soluție au propus oamenii de știință pentru Inteligența Artificială scăpată de sub control</h2>

			<p>Ei propun construirea unui fel de „algoritm de izolare” care simulează comportamentul periculos al algoritmului și îl blochează să facă orice dăunător – dar pentru că acesta ar trebui să fie cel puțin la fel de puternic ca primul algoritm, oamenii de știință au declarat că problema este imposibil de rezolvat, conform Futurism.</p>

			<p>Totul este însă doar o dezbatere teoretică. O inteligență artificială (AI) suficient de avansat pentru a amenința omenirea este probabil încă departe, dar oamenii foarte deștepți lucrează din greu la asta. Asta îl face subiectul perfect pentru a dezbate în avans, desigur. Ne-am dori să cunoaștem pericolul înainte ca acesta să sosească.</p>

			<p>„O mașină superinteligentă care controlează lumea sună ca o ficțiune științifică”, a spus co-autorul studiului Manuel Cebrian, liderul grupului de mobilizare digitală de la Centrul pentru oameni și mașini al Institutului Max Planck pentru Dezvoltare Umană.</p>
			
			<p>„Dar există deja mașini care îndeplinesc anumite sarcini importante în mod independent, fără ca programatorii să înțeleagă pe deplin cum au învățat-o. Prin urmare, se pune întrebarea dacă acest lucru ar putea deveni la un moment dat incontrolabil și periculos pentru umanitate”, a adăugat el.</p>

			</article>

	</section>
	<footer class="container3"><b>Copyright © Andreea </b> (articole preluate de pe descopera.ro)</footer>
</body>
</html>